# Corpus
Word Embedding benchmark project By Shahid Beheshti University NLP Lab

Please read [Our Wiki Page](https://github.com/sehsanm/embedding-benchmark/wiki) for more information

## Wiki Dump
WikiDump is a complete copy of all Wikimedia wikis, in the form of wikitext source and metadata embedded in XML. A good and public resource for academic researching.
    
This link contains the extracted text from FaWiki XML file.
    
First, we extracted the text data. Next, we normalized it and simply segmented its sentences using regular expressions.
    
You can download the corpus using this [LINK](https://sbuacir-my.sharepoint.com/personal/se_mahmoudi_sbu_ac_ir/_layouts/15/download.aspx?SourceUrl=%2Fpersonal%2Fse_mahmoudi_sbu_ac_ir%2FDocuments%2Fsbunlp%2FwikiDump_dotSplitData_Nikvand.zip) here
